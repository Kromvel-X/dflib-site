[#jdbc]
== Using Relational Databases

Relational databases are arguably the most important type of data stores out there. Also they happen to map
really well to DataFrames. DFLib provides advanced support for loading and saving DataFrames to RDBMS. It supports
transactions, auto-generation of certain SQL statements, merging of data on top of the existing data
("create-or-update"), building custom SQL for selects and updates. It knows how to treat different DB
"flavors" and does a number of other cool database-related things.

To start using all this, you need to import `dflib-jdbc` module:
[source,xml]
----
<dependency>
    <groupId>org.dflib</groupId>
    <artifactId>dflib-jdbc</artifactId>
</dependency>

<!-- Of course you also need to import your preferred JDBC driver -->
----

=== JdbcConnector

Once the imports are setup, you'd use `Jdbc` class to obtain an instance of `JdbcConnector` that can be later used for
all DB operations. You may already have a preconfigured `javax.sql.DataSource`, so the simplest way to create a
connector is to pass that DataSource to `Jdbc` factory method:

[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=connectorDS]
----
Alternatively you can build everything from scratch:
[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=connectorManual]
----

<1> (Optional) Driver name. Some drivers are not properly registered with the DriverManager, and require an explicit
declaration.
<2> DB account username/password (not needed for our in-memory Derby example, but will definitely be required for a real database).


=== TableLoader / TableSaver
Once you have the connector, you can start reading and persisting DataFrame data. Many DataFrames map directly to
individual tables (or views) defined in the database. For those DFLib provides a set of rather straightforward
operations that do not require the user to write SQL (all needed SQL is auto-generated by the framework):

[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=tableLoader]
----
----
id name              salary
-- ----------------- --------
 1 Jerry Cosin       70000.0
 2 Juliana Walewski  85000.0
 3 Joan O'Hara       101000.0
3 rows x 3 columns
----

Table loader provides a way to customize the load operation. It allows to select specific columns, set the maximum
number of rows to read, sample rows, and even specify fetch condition as another DataFrame. Some examples:
[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=tableLoader_wOptions]
----
----
name        salary
----------- --------
Jerry Cosin 70000.0
Joan O'Hara 101000.0
2 rows x 2 columns
----

What it doesn't require (unlike <<csv,CSV loader>>) is explicit column types, as the proper value types are inferred
from the database metadata.

Table saver allows to save DataFrame to a table. Column names in the DataFrame should match column names in the DB table:
[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=tableSaver]
----

In this scenario table saver executes insert for each DataFrame row. But what if there is already an existing data
in the table? There are a few options the user has to overwrite or merge the data:

* Append the data (that's what we effectively did above).
* Delete all existing data before doing the insert.
* Merge the data by comparing DataFrame and DB table data on PK column(s) or an arbitrary set of columns. Insert missing
rows, update the existing rows. If the table has more columns than there are columns in the DataFrame, the data in those
extra columns is preserved.

Delete before insert example:
[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=tableSaver_Delete]
----

Merge by PK example (PK columns are detected from DB metadata) :
[source,java,indent=0]
----
include::../../../test/java/org/dflib/docs/JdbcTest.java[tags=tableSaver_Merge]
----

=== SqlLoader / SqlSaver

TODO
